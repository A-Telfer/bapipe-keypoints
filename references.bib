
@techreport{pereira_sleap_2020,
	title = {{SLEAP}: {Multi}-animal pose tracking},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {{SLEAP}},
	url = {https://www.biorxiv.org/content/10.1101/2020.08.31.276246v1},
	abstract = {The desire to understand how the brain generates and patterns behavior has driven rapid methodological innovation to quantify and model natural animal behavior. This has led to important advances in deep learning-based markerless pose estimation that have been enabled in part by the success of deep learning for computer vision applications. Here we present SLEAP (Social LEAP Estimates Animal Poses), a framework for multi-animal pose tracking via deep learning. This system is capable of simultaneously tracking any number of animals during social interactions and across a variety of experimental conditions. SLEAP implements several complementary approaches for dealing with the problems inherent in moving from single-to multi-animal pose tracking, including configurable neural network architectures, inference techniques, and tracking algorithms, enabling easy specialization and tuning for particular experimental conditions or performance requirements. We report results on multiple datasets of socially interacting animals (flies, bees, and mice) and describe how dataset-specific properties can be leveraged to determine the best configuration of SLEAP models. Using a high accuracy model ({\textless}2.8 px error on 95\% of points), we were able to track two animals from full size 1024 × 1024 pixel frames at up to 320 FPS. The SLEAP framework comes with a sophisticated graphical user interface, multi-platform support, Colab-based GPU-free training and inference, and complete tutorials available, in addition to the datasets, at sleap.ai.},
	language = {en},
	urldate = {2022-05-24},
	institution = {bioRxiv},
	author = {Pereira, Talmo D. and Tabris, Nathaniel and Li, Junyu and Ravindranath, Shruthi and Papadoyannis, Eleni S. and Wang, Z. Yan and Turner, David M. and McKenzie-Smith, Grace and Kocher, Sarah D. and Falkner, Annegret L. and Shaevitz, Joshua W. and Murthy, Mala},
	month = sep,
	year = {2020},
	doi = {10.1101/2020.08.31.276246},
	note = {Section: New Results
Type: article},
	pages = {2020.08.31.276246},
	file = {Full Text PDF:/home/andretelfer/Zotero/storage/DW284I72/Pereira et al. - 2020 - SLEAP Multi-animal pose tracking.pdf:application/pdf;Snapshot:/home/andretelfer/Zotero/storage/C4VY3NKJ/2020.08.31.276246v1.html:text/html},
}

@article{mathis_deeplabcut_2018,
	title = {{DeepLabCut}: markerless pose estimation of user-defined body parts with deep learning},
	volume = {21},
	issn = {1097-6256, 1546-1726},
	shorttitle = {{DeepLabCut}},
	url = {http://www.nature.com/articles/s41593-018-0209-y},
	doi = {10.1038/s41593-018-0209-y},
	language = {en},
	number = {9},
	urldate = {2022-05-24},
	journal = {Nature Neuroscience},
	author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M. and Abe, Taiga and Murthy, Venkatesh N. and Mathis, Mackenzie Weygandt and Bethge, Matthias},
	month = sep,
	year = {2018},
	pages = {1281--1289},
	file = {Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf:/home/andretelfer/Zotero/storage/P9R5EMAB/Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf:application/pdf},
}

@article{sturman_deep_2020,
	title = {Deep learning-based behavioral analysis reaches human accuracy and is capable of outperforming commercial solutions},
	volume = {45},
	copyright = {2020 The Author(s)},
	issn = {1740-634X},
	url = {https://www.nature.com/articles/s41386-020-0776-y},
	doi = {10.1038/s41386-020-0776-y},
	abstract = {To study brain function, preclinical research heavily relies on animal monitoring and the subsequent analyses of behavior. Commercial platforms have enabled semi high-throughput behavioral analyses by automating animal tracking, yet they poorly recognize ethologically relevant behaviors and lack the flexibility to be employed in variable testing environments. Critical advances based on deep-learning and machine vision over the last couple of years now enable markerless tracking of individual body parts of freely moving rodents with high precision. Here, we compare the performance of commercially available platforms (EthoVision XT14, Noldus; TSE Multi-Conditioning System, TSE Systems) to cross-verified human annotation. We provide a set of videos—carefully annotated by several human raters—of three widely used behavioral tests (open field test, elevated plus maze, forced swim test). Using these data, we then deployed the pose estimation software DeepLabCut to extract skeletal mouse representations. Using simple post-analyses, we were able to track animals based on their skeletal representation in a range of classic behavioral tests at similar or greater accuracy than commercial behavioral tracking systems. We then developed supervised machine learning classifiers that integrate the skeletal representation with the manual annotations. This new combined approach allows us to score ethologically relevant behaviors with similar accuracy to humans, the current gold standard, while outperforming commercial solutions. Finally, we show that the resulting machine learning approach eliminates variation both within and between human annotators. In summary, our approach helps to improve the quality and accuracy of behavioral data, while outperforming commercial systems at a fraction of the cost.},
	language = {en},
	number = {11},
	urldate = {2022-05-24},
	journal = {Neuropsychopharmacology},
	author = {Sturman, Oliver and von Ziegler, Lukas and Schläppi, Christa and Akyol, Furkan and Privitera, Mattia and Slominski, Daria and Grimm, Christina and Thieren, Laetitia and Zerbi, Valerio and Grewe, Benjamin and Bohacek, Johannes},
	month = oct,
	year = {2020},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Anxiety, Behavioural methods},
	pages = {1942--1952},
	file = {Full Text PDF:/home/andretelfer/Zotero/storage/47J8TVJE/Sturman et al. - 2020 - Deep learning-based behavioral analysis reaches hu.pdf:application/pdf;Snapshot:/home/andretelfer/Zotero/storage/7UNE2RRP/s41386-020-0776-y.html:text/html},
}
